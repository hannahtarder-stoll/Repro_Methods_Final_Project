---
title: "Flexible Multi-Step Prediction and Integration During Navigation"
author: "Hannah Tarder-Stoll"
date: "December 6th, 2018"
output: 
  html_document:
    theme: cerulean 
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

baseDir<-getwd()

source("pred_nav_analysis.R")

#load packages
library(ggplot2)
library(tidyverse)
library(gridExtra)

#setwd back to the main directory
setwd(baseDir)
```

Memory for previous experiences does not merely allow us to reflect on our past, but enables preparation for the future. One way in which this is accomplished is through prediction: knowledge of sequential structure in our environment enables anticipation of upcoming events. For example, when we are navigating from our house to the grocery store, we can predict upcoming locations on our route. Evidence for prediction of upcoming events has been shown across multiple brain regions such as the hippocampus, mPFC, and visual cortex (Johnson & Redish, 2007; Brown et al., 2016; Long, Lee & Kuhl, 2016; Hindy, Ng & Turk-Browne, 2016). 

For efficient planning, however, we should predict multiple steps into the future simultaneously. For example, when navigating from our house to the grocery store, we may predict which event is occurring next, such as an upcoming intersection, and which events are occurring farther in the future, such as arriving at the grocery store. What are the neural underpinnings of multi-step prediction? It is postulated that the brain represents retrospective information on a hierarchy, with shorter timescale information represented in posterior regions and longer timescale information in anterior regions (Hasson, Chen & Honey, 2015). An intriguing but unresolved question is whether the neural underpinnings of multi-step prediction rely on this cortical hierarchy as well. Further, it remains unknown how predictions are updated when we encounter new information about our environments. Memory integration, the process by which separate but related experiences become linked in the brain (Schlichting & Preston, 2015), is proposed to be enhanced by the strength of predictions (Schlichting, Mumford, & Preston, 2015; Long et al., 2016). Changes to pre-existing predictive representations after integration, however, have yet to be explored. The current study uses a novel paradigm to investigate the neural mechanisms of multi-step prediction, and how multi-step predictions are updated after memory integration. 

Evidence for forward prediction in the brain was first shown in rodent work investigating place cell firing. As rodents navigated a maze, place cells for upcoming locations, as opposed to place cells which reflect the rodent’s current location, fired in the hippocampus at a decision point (Johnson & Redish, 2007). This is thought to reflect prediction of upcoming events. Indeed, evidence for prediction in the hippocampus has been shown across many studies in both humans and non-human animals (Schapiro, Kustner & Turk-Browne, 2012; Pfeiffer & Foster, 2013; Brown et al., 2016; Kok & Turk-Browne, 2016;). Prediction has also been shown to occur across multiple other brain regions. For example, one study found evidence for strong neural predictions in the mPFC and PPC (Long et al., 2016). Other studies have shown that prediction can happen in lower order regions such as the visual cortex (Hindy et al., 2016; Kok, Jehee & de Lange, 2012). 

In a seminal paper on forward prediction, participants navigated a well learned environment to reach navigational goals. At the start of navigation, participants were first asked to plan their route. During the planning period, it was found that the hippocampus and OFC represented the upcoming goal location, reflecting prospection. Importantly, this was not only found for the goal location, but for other locations that participants would traverse on that route, known as sub-goals (Brown et al., 2016). This provides preliminary evidence for the neural representation of multi-step prediction, but Brown et al. (2016) only showed prediction two steps into the future—the goal and the sub-goal. Further, they did not study how the timescale of these predictions vary across brain regions (Brown et al., 2016).
 
A separate body of work on information representation may provide a window into understanding the timescale of multi-step prediction. Recently, theories on information processing in the brain have been gaining traction. These theories postulate that we acquire information from our environment at multiple timescales, and different brain regions process this information within distinct temporal receptive windows. Lower order regions such as early sensory areas process information on short timescales, while higher order regions process information on long timescales (Hasson et al., 2015). This cortical hierarchy of information processing has been shown for narrative processing (Chen et al., 2016), as well as the granularity at which we segment events (Baldassano et al., 2017). A similar hierarchy has been proposed within the hippocampal long axis: fine grained information may be represented in the posterior hippocampus while coarse grained information is represented in the anterior hippocampus (Poppenk et al., 2013; Strange et al., 2014). Indeed, a recent study investigated hippocampal activity as participants navigated familiar routes. Consistent with a processing hierarchy in the hippocampal long axis, they found evidence for short timescale information in posterior hippocampus and long timescale information in anterior hippocampus (Brunec et al., 2018). This cortical hierarchy, however, has only been investigated for the accumulation of retrospective information. Bridging work on prediction and information processing, this study aims to extend evidence for a representational hierarchy to prospective information. We propose that multi-step prediction may be represented across this cortical hierarchy, with lower order regions and posterior hippocampus representing prediction fewer steps into the future than higher order regions and anterior hippocampus. 

The second question this study seeks to address is how neural predictions are updated when our environments are updated with new information. One way in which this can occur is the process of memory integration, whereby two separate but related experiences can become linked in the brain (Schlichting & Preston, 2015). Memory integration has been shown to involve, among other regions, the hippocampus and mPFC (Zeithamova, Dominick & Preston, 2012), two regions which are also implicated in prediction (Long et al., 2016). Indeed, previous work has strongly suggested that prediction plays an important role in memory integration (Schlichting et al., 2015), and it has been shown that the strength of neural predictions is positively correlated with successful memory integration (Long et al., 2016). However, it has yet to be shown how integration influences prediction. Can integration update our predictions, and if so, how rapidly? 

If predictions are updated after integration, a critical question is how this is achieved. On one hand, theories of sequence learning propose that predictions are built up slowly, after multiple, repeated experiences (Davachi & Dubrow, 2015). This is consistent with findings from statistical learning tasks. For example, there is evidence of forward prediction for items in a structured sequence after multiple exposures to that sequence (Schapiro et al., 2012). This perspective suggests that predictions are built up slowly over time and multiple learning experiences. On the other hand, episodic memory integration provides evidence for mnemonic updating after a single shot learning experience, such as in the associative inference paradigm. In this paradigm, participants learn that A and B go together. They then learn that A and C also go together, providing an indirect link between B and C (Schlichting & Preston, 2015; Duncan & Schlichting, 2018). Indeed, it has been shown that hippocampal-mPFC representations are altered after new information is integrated into existing memories (Milivojevic, Vicente-Grabovetsky & Doeller, 2015). Following this logic, predictions about upcoming events may be updated rapidly upon encountering new information. Although memory integration has been well studied, the lasting effects of integration on mnemonic predictions have yet to be investigated. 

In the current study, we leverage neural evidence for processing hierarchies, prediction, and memory integration to make novel predictions about the flexible use of multi-step predictions behaviourally. Here, we approach these questions using a novel, naturalistic paradigm. On day one, participants learn to navigate through a series of rooms in virtual reality in two maps. Critically, these rooms have a constant order, allowing participants to predict upcoming rooms on their route. On day 2, participants predict rooms in the sequence in a behavioural task. We then give them linking information to integrate the two maps into a cohesive whole, and have them predict using the integrated map. We hypothesize that multi-step predictions will be represented on a cortical hierarchy, with lower order regions predicting fewer steps into the future than higher order regions. We further predict that integration will update predictions. However, this updating could happen slowly, requiring time and experience, or quickly, as a result of single shot learning.
  
## Method

### Participants

Participants included seven young adults recruited from the Columbia University area and were compensated \$15/hour for their participation in the study. All participants gave consent in accordance with the Columbia University Institutional Review Board. 

### Procedure 

To investigate multi-step prediction, participants completed three behavioral tasks over two days: an encoding phase, a prediction phase, and an integration phase (Figure 1). The encoding phase took place on day one and employed the of immersive virtual reality and the prediction phase and integration phase took place on day two. 

On day one, participants encoded the order of rooms in virtual reality using an Oculus rift. They learned two maps, Map A and Map B, which each contained 8 distinct rooms (Figure 1a). Critically, the order of rooms in each map remained constant throughout the experiment, allowing participants to predict upcoming rooms in the sequence. The identity and order of rooms in Map A and B were randomized across participants. Within each map (A and B), participants learned two trajectories: the Green Path and the Blue Path (Figure 1a). Critically, the Green and Blue paths contained the exact same rooms but in a different order. This will allow us to determine whether predictions are path-specific. Therefore, each participant learned a total of four sequences (Map A Green, Map A Blue, Map B Green, Map B Blue). Participants were told that their goal was to learn and memorize the order of the rooms in all sequences. To help participants encode the sequences, participants were instructed to generate distinct and detailed stories to link the rooms in order. 

Participants first generated a story for Map A Green and then experienced the order in immersive virtual reality six times. They then repeated this procedure for Map A Blue. Participants were then taken out of VR and asked to recall the order of the Map A sequences. Participants then completed the same procedure for Map B Green and Map B Blue. During learning in virtual reality, participants were placed in the starting room for the given sequence (e.g. room one of Map A Green). After five seconds, one green sphere and one blue sphere appeared. Participants were instructed to reach out with their virtual hands and touch either the green or blue sphere, depending on which path they were learning in the trial. This teleported them to the next room in the order Figure 1b). After 20% of VR trials, participants were shown pictures of two upcoming rooms and are asked to indicate which room is coming up sooner in the order to ensure they were learning the sequence. The encoding phase took approximately 1.5 hours to complete. 

Participants then returned 24 hours later for the prediction and integration phases. Participants first recalled the order of all four sequences, and the stories that linked them in order. Participants then completed the Prediction Phase. Participants were shown a room from either Map A or Map B with a path cue (Green or Blue) for 3 seconds. This was followed by a completely black screen for a variable duration of 5 to 9 seconds. They then saw two pictures of upcoming rooms from 1 to 5 rooms in the future and were instructed to respond which room was coming up sooner in the order (Figure 1c). Critically, participants only had 3 seconds to respond. However, participants were told they could use the black screen period to “prepare their response”, giving participants time to predict upcoming rooms in the order. Participants completed 2 blocks of the prediction phase, and they were tested on each room from each of the four sequences in each run, lasting approximately 21 minutes in total. 

Next, participants completed the Integration Phase. In the integration phase, participants were told that new connections had been formed, opening a "portal" between Map A and Map B on either the blue or the green path. This forced participants to integrate the two maps into a coherent whole. Participants watched two videos which showed them which room in Map A was now linked to which room in Map B, and vice versa (Map B to Map A). Each participant integrated ony the blue path or the green path, with the non-integrated path serving as a control condition. The integrated path was counterbalanced across participants. The rooms that served as the "integration bridge" (i.e. room in Map A which linked to a room in Map B) were chosen randomly across participants. Critically, participants were told that the old connections from the "integration bridge" rooms no longer work. This means that, from this single shot learning experience, participants must now predict multiple steps into Map B from Map A and into Map A from Map B. Finally, participants then completed four additional runs of the prediction phase, but this time participants were required to predict into the integrated map (i.e. predict into Map B from Map A) to get the correct response on the integrated path (either blue or green). Everything else about the prediction phase remained the same. 

```{r, echo=FALSE}
knitr::include_graphics('schematic.png')
```

## Results

To determine whether participants generate and use predictions at multiple timescales, we first analyzed behaviour from the Prediction Phase. As this dataset only contained seven participants, here we present only descriptive statistics along with visualizations as our power is too low to run inferential statistics. 

Firstly, to determine whether participants generated predictions, we calculated overall accuraccy for the prediction phase. All participants were able to learn the sequence, and successfully generated predictions about upcoming rooms in the sequence at a range of timescales(M = `r round(mean(acc$mean_acc), digits =2)`, SD = `r round(sd(acc$mean_acc), digits =2)`). Next,as participants learned two maps (Map A and Map B), we calculated prediction phase accuracy for Map A and Map B, respectively. We found that, numerically, there was no difference in performance for Map A blocks (M = `r round(mean(acc_map$A), digits =2)`, SD = `r round(sd(acc_map$A), digits =2)`)  vs. Map B blocks (M = `r round(mean(acc_map$B), digits =2)`, SD = `r round(sd(acc_map$B), digits =2)`) in the prediction test, indicating participants learned the sequences in both maps. Participants also learned two paths within a map (Green Path and Blue Path). We found that, numerically, performance was similar for Green Path blocks (M = `r round(mean(acc_path$green), digits =2)`, SD = `r round(sd(acc_path$green), digits =2)`) vs. Blue Path blocks (M = `r round(mean(acc_path$blue), digits =2)`, SD = `r round(sd(acc_path$blue), digits =2)`) in the prediction test across participants (Figure 2). This indicates that (1) there was no retroactive or proactive interference due to the order in which the paths were learned and, critically, (2) participants used context to successfully guide which predictions were used when multiple predictions were available. 

```{r, out.width = "800px", echo=FALSE}
plot_path #accuracy for green/blue paths
```

*Figure 2* Accuracy for Green and Blue Paths. Participants' performance was equivalent for the Green and Blue paths. This inidcates that, as expected, participants can use context (green context or blue context) to flexibly guide which predictions to use.


We were next able to test whether the amount of prediction time, the distance into the future of the correct answer, and the interaction of the two influenced performance on the prediction test. We found that the prediction time (5, 6, 7, or 8 seconds) did not appear to numerically influence accuracy on the prediction test (5: M = `r round(mean(acc_pred_time$five), digits=2)`, SD = `r round(sd(acc_pred_time$five), digits=2)`; 6: M = `r round(mean(acc_pred_time$six), digits=2)`, SD = `r round(sd(acc_pred_time$six), digits=2)`; 7: M = `r round(mean(acc_pred_time$seven), digits=2)`, SD = `r round(sd(acc_pred_time$seven), digits=2)`; 8: M = `r round(mean(acc_pred_time$eight), digits=2)`,  SD = `r round(sd(acc_pred_time$eight), digits=2)`). However, the distance into the future of the correct answer (1, 2, 3, or 4 rooms ahead in the sequence) did numerically influence accuracy. Performance was mostly equivalent for 1 (M = `r round(mean(acc_future$one), digits=2)`, SD = `r round(sd(acc_future$one), digits=2)`), 2 (M = `r round(mean(acc_future$two), digits=2)`, SD = `r round(sd(acc_future$two), digits=2)`), and 3 (M = `r round(mean(acc_future$three), digits=2)`, SD = `r round(sd(acc_future$three), digits=2)`) rooms into the future. However, performance was numerically lower for 4 rooms into the future (M = `r round(mean(acc_future$four), digits=2)`, SD = `r round(sd(acc_future$four), digits=2)`; Figure 3). Interestingly, there was an interaction between prediction time and number of rooms ahead the correct answer was: accuracy for 4 rooms into the future lowest for the shortest prediction time (M = `r round(mean(acc_time_four$five, na.rm=T), digits=2)`, SD = `r round(sd(acc_time_four$five, na.rm=T), digits=2)`), and increased with the amount of prediction time (M = `r round(mean(acc_time_four$eight), digits=2)`, SD = .`r round(sd(acc_time_four$eight), digits=2)`; See Figure 4). 

```{r, out.width="800px", echo=FALSE}
plot_distance #accuracy for correct distance into future 
```

*Figure 3* Accuracy for Number of Steps into the Future. Participants' performance was similar on trials that required participants to predict one to three rooms ahead in the sequence, but were numerically worse on trials that required prediction four rooms ahead. 

```{r, out.width="800px", echo=FALSE}
plot_distance_time #accuracy for correct distance into future x pred time
```

*Figure 4* Accuracy for Prediction Time by Number of Steps into the Future. When participants are given less time to predict (e.g. 5 seconds), their performance is worse for trials where they have to predict farther into the future (e.g 4 rooms into the future). However, as prediction time increases, so does accuracy on these farther trials. Conversely, long prediction times do not decrease performance on trials where participants predict close rooms (i.e. 1 room into the future)


We next turned to our second question of interest: how are predictions updated after memory integration? To answer this question, we analyzed the behviaoural data from the integration portion of the experiment. Collapsing across both the integrated and non-integrated paths across participants, performance was much higher than chance (50%), but numerically lower than in the prediction task (M = `r round(mean(acc_int$mean_acc), digits=2)`, digits=2), SD = `r round(sd(acc_int$mean_acc), digits=2)`). Participants did numerically better on the non-integrated path (M = `r round(mean(acc_int_noint$No_Int), digits=2)`, SD = `r round(sd(acc_int_noint$No_Int), digits=2)`) than on the integrated path (M = `r round(mean(acc_int_noint$Int), digits=2)`, SD = `r round(sd(acc_int_noint$Int), digits=2)`; Figure 5), which is to be expected as the integration condition is more difficult and requires the flexible use of previously learned predicitons. 

```{r, out.width="800px", echo = FALSE}
plot_int_noInt #int vs no int cond
```

*Figure 5* Accuracy for Integration and No Integration Conditions. Participants performance was worse for the integration as compared to the no integration condition. However, given the difficulty of the integration condtion, the difference between the two conditions is not as large as would be expected. 

As a proxy for understanding the timescale on which predictions are updated after integration, we looked at accuracy across each run of the integration test. As can be seen in Figure 6, accuracy increased as run number increased for almost all of the participants (Run 1: `r round(mean(acc_run_int$one), digits=2)`, SD = `r round(sd(acc_run_int$one), digits=2)`; Run 4: `r round(mean(acc_run_int$four, na.rm=T), digits=2)`, SD = `r round(sd(acc_run_int$four, na.rm=T), digits=2)`). Further, accuracy was lower in the first two blocks for the integration (M = `r round(first_half_int, digits=2)`) as compared to the non-integration (M = `r round(first_half_noint, digits=2)`), but accuracy converged for both integration (M = `r round(second_half_int, digits=2)`) and non-integration (M = `r round(second_half_noint, digits=2)`) in the third and fourth blocks. This indicates that, over time, participants updated their predictions after integration. The selective increase in accuracy for the integration condition across runs can be seen in the interactive figure below (Figure 7).  
  

```{r, out.width = "800px", echo=FALSE}
#plots for the integration portion
plot_run_int #accuracy for runs (spag plot)
```

*Figure 6* Accuracy on the Integration Test Across Runs. Performance for nearly all participants improves as a function of run number on the integration test. Importantly, participants only learn the integrating links between maps A and B once. This indicates that, even after a single shot learning experience, predictions are updated over time to reflect updated strucutre in our environemnts. 

```{r, echo = FALSE}
#shiny plot to look at plots by run
#remake integration data to prepare for shiny

shiny_prep<-cast(int_data, participant + Int_All_Runs.thisN + cond~., mean, value = "acc", na.rm=T, subset = (cond != ""))
colnames(shiny_prep)[colnames(shiny_prep)=="(all)"] <- "mean_acc"
shiny_prep$Run_1<-ifelse(shiny_prep$Int_All_Runs.thisN == 0, TRUE, FALSE)
shiny_prep$Run_2<-ifelse(shiny_prep$Int_All_Runs.thisN == 1, TRUE, FALSE)
shiny_prep$Run_3<-ifelse(shiny_prep$Int_All_Runs.thisN == 2, TRUE, FALSE)
shiny_prep$Run_4<-ifelse(shiny_prep$Int_All_Runs.thisN == 3, TRUE, FALSE)

shiny_bar_prep<-cast(int_data, cond~., mean, value = "acc", na.rm=T, subset = (cond != ""))
colnames(shiny_bar_prep)[colnames(shiny_bar_prep)=="(all)"] <- "mean_acc"

inputPanel(
  selectInput("Run", label = "Integration Activity by Run:",
              choices = c("Run_1", "Run_2", "Run_3", "Run_4"),
              selected = "Run_1")
)

renderPlot({
  ggplot(data = shiny_prep, aes(cond, mean_acc)) +
    #geom_bar(data=shiny_bar_prep, aes(y=mean_acc,x=cond),fill  = "white", color = "black", stat = "identity", width = 0.5) +
    geom_violin(fill = "grey", alpha = 0.3) +
    geom_point(aes_string(color = input$Run), alpha=0.8, size=5, position = position_jitter(w = 0.15, h = 0)) +
    theme_classic(base_size = 22) +
    xlab("Condition") +
    ylab("Accuracy (%)") 
})
```

*Figure 7* Accuracy on Integration vs. No Integration Condition by Run. As run number increases, accuracy for that specific run (blue points) does not increase in the no integration condition substantially. By contrast, increasing run number reveals a large increase in accuracy for that run (blue points) in the integration condition. This indicates that performance on the integration condition specifically is driving the improvement across runs, and that predictions are being updated to reflect the new structure of the environment.  

## References
Baldassano, C., Chen, J., Zadbood, A., Pillow, J. W., Hasson, U., & Norman, K. A. (2017). Discovering Event Structure in Continuous Narrative Perception and Memory. Neuron, 95(3), 709–721.e5. https://doi.org/10.1016/j.neuron.2017.06.041

Bar, M. (2009). The proactive brain: memory for predictions. Philosophical Transactions of the Royal Society B: Biological Sciences, 364(1521), 1235. https://doi.org/10.1098/RSTB.2008.0310

Brown, T. I., Carr, V. A., LaRocque, K. F., Favila, S. E., Gordon, A. M., Bowles, B., … Wagner, A. D. (2016). Prospective representation of navigational goals in the human hippocampus. Science (New York, N.Y.), 352(6291), 1323–1326. https://doi.org/10.1126/science.aaf0784

Brunec, I. K., Bellana, B., Ozubko, J. D., Man, V., Robin, J., Liu, Z.-X., … Moscovitch, M. (2018). Multiple Scales of Representation along the Hippocampal Anteroposterior Axis in Humans. Current Biology, 28, 2129–2135.e6. https://doi.org/10.1016/j.cub.2018.05.016

Buckner, R. L., & Carroll, D. C. (2007). Self-projection and the brain. Trends in Cognitive Sciences, 11(2), 49–57. https://doi.org/10.1016/j.tics.2006.11.004

Chen, J., Honey, C. J., Simony, E., Arcaro, M. J., Norman, K. A., & Hasson, U. (2016). Accessing Real-Life Episodic Information from Minutes versus Hours Earlier Modulates Hippocampal and High-Order Cortical Dynamics. Cerebral Cortex, 26(8), 3428–3441. https://doi.org/10.1093/cercor/bhv155

Chen, J., Hasson, U., & Honey, C. J. (2015). Processing Timescales as an Organizing Principle for Primate Cortex. Neuron, 88(2), 244–246. https://doi.org/10.1016/j.neuron.2015.10.010

Cowell, R., Barense, M., & Sadil, P. (n.d.). A Roadmap for Understanding Memory: Decomposing Cognitive Processes into Operations and Representations. https://doi.org/10.31234/OSF.IO/B7E8K

Davachi, L., & DuBrow, S. (2015). How the hippocampus preserves order: the role of prediction and context. Trends in Cognitive Sciences, 19(2), 92–99. https://doi.org/10.1016/j.tics.2014.12.004

Duncan, K. D., & Schlichting, M. L. (2018). Hippocampal representations as a function of time, subregion, and brain state. Neurobiology of Learning and Memory, 153(Pt A), 40–56. https://doi.org/10.1016/j.nlm.2018.03.006

Hasson, U., Chen, J., & Honey, C. J. (2015). Hierarchical process memory: memory as an integral component of information processing. Trends in Cognitive Sciences, 19(6), 304–313. https://doi.org/10.1016/j.tics.2015.04.006

Hindy, N. C., Ng, F. Y., & Turk-Browne, N. B. (2016). Linking pattern completion in the hippocampus to predictive coding in visual cortex. Nature Neuroscience, 19(5), 665–667. https://doi.org/10.1038/nn.4284

Johnson, A., & Redish, A. D. (2007). Neural Ensembles in CA3 Transiently Encode Paths Forward of the Animal at a Decision Point. Journal of Neuroscience, 27(45), 12176–12189. https://doi.org/10.1523/JNEUROSCI.3761-07.2007

Kok, P., Jehee, J. F. M., & de Lange, F. P. (2012). Less Is More: Expectation Sharpens Representations in the Primary Visual Cortex. Neuron, 75(2), 265–270. https://doi.org/10.1016/j.neuron.2012.04.034

Kok, P., & Turk-Browne, N. B. (2018). Associative Prediction of Visual Shape in the Hippocampus. The Journal of Neuroscience : The Official Journal of the Society for Neuroscience, 38(31), 6888–6899. https://doi.org/10.1523/JNEUROSCI.0163-18.2018

Kriegeskorte, N., Mur, M., & Bandettini, P. (2008). Representational Similarity Analysis – Connecting the Branches of Systems Neuroscience. Frontiers in Systems Neuroscience, 2, 4. https://doi.org/10.3389/NEURO.06.004.2008

Long, N. M., Lee, H., Brice, X., & Kuhl, A. (2016). Hippocampal Mismatch Signals Are Modulated by the Strength of Neural Predictions and Their Similarity to Outcomes. https://doi.org/10.1523/JNEUROSCI.1850-16.2016

Milivojevic, B., Vicente-Grabovetsky, A., & Doeller, C. F. (2015). Insight Reconfigures Hippocampal-Prefrontal Memories. Current Biology, 25(7), 821–830. https://doi.org/10.1016/j.cub.2015.01.033

Pfeiffer, B. E., & Foster, D. J. (2013). Hippocampal place-cell sequences depict future paths to remembered goals. Nature, 497(7447), 74–79. https://doi.org/10.1038/nature12112

Poppenk, J., Evensmoen, H. R., Moscovitch, M., & Nadel, L. (2013). Long-axis specialization of the human hippocampus. Trends in Cognitive Sciences, 17(5), 230–240. https://doi.org/10.1016/j.tics.2013.03.005

Schapiro, A. C., Kustner, L. V., & Turk-Browne, N. B. (2012). Shaping of Object Representations in the Human Medial Temporal Lobe Based on Temporal Regularities. Current Biology, 22(17), 1622–1627. https://doi.org/10.1016/j.cub.2012.06.056

Schlichting, M. L., & Preston, A. R. (2015). Memory integration: neural mechanisms and implications for behavior. Current Opinion in Behavioral Sciences, 1, 1–8. https://doi.org/10.1016/j.cobeha.2014.07.005

Schlichting, M. L., Mumford, J. A., & Preston, A. R. (2015). Learning-related representational changes reveal dissociable integration and separation signatures in the hippocampus and prefrontal cortex. Nature Communications, 6(1), 8151. https://doi.org/10.1038/ncomms9151

Strange, B. A., Witter, M. P., Lein, E. S., & Moser, E. I. (2014). Functional organization of the hippocampal longitudinal axis. Nature Reviews Neuroscience, 15(10), 655–669. https://doi.org/10.1038/nrn3785

Zeithamova, D., Dominick, A. L., & Preston, A. R. (2012). Hippocampal and ventral medial prefrontal activation during retrieval-mediated learning supports novel inference. Neuron, 75(1), 168–179. https://doi.org/10.1016/j.neuron.2012.05.010

